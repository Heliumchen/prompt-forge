import { useState, useCallback } from "react";
import { LLMClient } from "@/lib/openrouter";
import { toast } from "sonner";
import { Project } from "@/lib/storage";

export function usePromptReview() {
  const [isReviewing, setIsReviewing] = useState(false);
  const [selectedReviewModel, setSelectedReviewModel] = useState<string>(
    "google/gemini-2.5-pro",
  );
  const [reviewContent, setReviewContent] = useState<string>("");
  const [isStreamingReview, setIsStreamingReview] = useState(false);

  const validateReview = useCallback(
    (currentProject: Project | null, selectedReviewModel: string) => {
      if (!currentProject) {
        toast.error("è¯·é€‰æ‹©ä¸€ä¸ªé¡¹ç›®");
        return false;
      }

      if (!selectedReviewModel) {
        toast.error("è¯·é€‰æ‹©ä¸€ä¸ªæ¨¡åž‹");
        return false;
      }

      const apiKeysStr = localStorage.getItem("apiKeys");
      if (!apiKeysStr) {
        toast.error("è¯·åœ¨è®¾ç½®ä¸­é…ç½®OpenRouter APIå¯†é’¥");
        return false;
      }

      const apiKeys = JSON.parse(apiKeysStr);
      const apiKey = apiKeys.OpenRouter;

      if (!apiKey) {
        toast.error("è¯·åœ¨è®¾ç½®ä¸­é…ç½®OpenRouter APIå¯†é’¥");
        return false;
      }

      return apiKey;
    },
    [],
  );

  const handlePromptReview = useCallback(
    async (currentProject: Project | null) => {
      const apiKey = validateReview(currentProject, selectedReviewModel);
      if (!apiKey) return;

      const currentVersion = currentProject!.versions.find(
        (v) => v.id === currentProject!.currentVersion,
      );
      if (!currentVersion) {
        toast.error("å½“å‰ç‰ˆæœ¬ä¸å­˜åœ¨");
        return;
      }

      // ä½¿ç”¨åŽŸå§‹çš„promptsï¼ˆå¸¦placeholderï¼‰ï¼Œè€Œä¸æ˜¯å¡«å……å˜é‡åŽçš„prompts
      const originalPrompts = currentVersion.data.prompts || [];
      if (originalPrompts.length === 0) {
        toast.error("æ²¡æœ‰å¯è¯„ä¼°çš„æç¤ºè¯æ¨¡æ¿");
        return;
      }

      const promptTemplateContent = originalPrompts
        .map((prompt) => {
          return `**${prompt.role.toUpperCase()}:**\n${prompt.content}`;
        })
        .join("\n\n");

      setIsReviewing(true);
      setIsStreamingReview(true);
      setReviewContent("");

      try {
        const client = new LLMClient(apiKey);

        const messages = [
          {
            role: "system" as const,
            content: `ä½ æ˜¯ä¸€ä¸ªSystem Promptå¤§å¸ˆã€‚

ç”¨æˆ·ä¼šç»™ä½ å‘é€ä¸€æ®µSystem Promptï¼Œä½ éœ€è¦å¸®åŠ©ç”¨æˆ·åˆ†æžSystem Promptçš„çŽ°çŠ¶ï¼Œå¹¶ç»™å‡ºåˆç†çš„ã€å¯æ“ä½œçš„ä¼˜åŒ–å»ºè®®ã€‚

## ä»·å€¼å–å‘
æƒœå­—å¦‚é‡‘ï¼Œèƒ½ç”¨ä¸€ä¸ªå­—è®²æ¸…æ¥šçš„äº‹æƒ…ï¼Œç»ä¸ç”¨æ›´å¤šå­—ï¼›ç”¨è¯çš„å‡†ç¡®éžå¸¸é‡è¦
é€»è¾‘æ¸…æ™°ï¼Œä¸»æ¬¡åˆ†æ˜Žï¼Œèƒ½æ•é”æ´žå¯Ÿåˆ°system promptä¸­çŸ›ç›¾å†²çªçš„åœ°æ–¹
æ·±è°™å¤§æ¨¡åž‹å·¥ä½œåŽŸç†ï¼Œå¯¹å¤§æ¨¡åž‹çš„èƒ½åŠ›è¾¹ç•Œæœ‰æ·±åˆ»ç†è§£

## è¾“å‡ºæ–¹å¼
è¦†ç›–ä»¥ä¸‹å†…å®¹ç»™å‡ºä½ çš„åˆ†æžåé¦ˆ
- æ•´ä½“è¯„ä»· (Overall Assessment)
- å¯ä¼˜åŒ–å»ºè®® (Suggestions for Improvement)
å»ºè®®å°½å¯èƒ½å…·ä½“å¯æ“ä½œï¼Œæ¯”å¦‚æŒ‡æ˜ŽæŠŠåŽŸå¥ä¸­çš„\`\`\`XXX\`\`\`æ”¹æˆ\`\`\`YYY\`\`\``,
          },
          {
            role: "user" as const,
            content: promptTemplateContent,
          },
        ];

        const options = {
          model: selectedReviewModel,
          stream: true,
          temperature: 0.7,
          max_tokens: 20480,
        };

        const isGeminiReasoning =
          selectedReviewModel.includes("gemini-2.5-pro");

        const stream = await client.chat(messages, options);

        let generatedText = "";
        let hasReceivedContent = false;
        let thinkingTimeout: NodeJS.Timeout | null = null;

        if (isGeminiReasoning) {
          thinkingTimeout = setTimeout(() => {
            if (!hasReceivedContent) {
              setReviewContent(
                "ðŸ¤” Reasoning models take longer time to generate a response, please wait...",
              );
            }
          }, 5000);
        }

        for await (const chunk of stream) {
          if (chunk) {
            if (!hasReceivedContent) {
              hasReceivedContent = true;
              if (thinkingTimeout) {
                clearTimeout(thinkingTimeout);
                thinkingTimeout = null;
              }
              if (isGeminiReasoning) {
                setReviewContent("");
                generatedText = "";
              }
            }
            generatedText += chunk;
            setReviewContent(generatedText);
          }
        }

        if (thinkingTimeout) {
          clearTimeout(thinkingTimeout);
        }

        if (!hasReceivedContent) {
          setReviewContent(
            "âš ï¸ æœªæ”¶åˆ°æ¨¡åž‹å“åº”ï¼Œå¯èƒ½æ˜¯reasoning modelè¿˜åœ¨å¤„ç†ä¸­ã€‚\n\nè¯·ç¨åŽé‡è¯•æˆ–å°è¯•å…¶ä»–æ¨¡åž‹ã€‚",
          );
          toast.warning("æœªæ”¶åˆ°æ¨¡åž‹å“åº”ï¼Œè¯·é‡è¯•");
        } else {
          toast.success("æç¤ºè¯è¯„ä¼°å®Œæˆ");
        }
      } catch (error: Error | unknown) {
        console.error("è¯„ä¼°é”™è¯¯:", error);
        toast.error(
          "è¯„ä¼°é”™è¯¯: " + (error instanceof Error ? error.message : "æœªçŸ¥é”™è¯¯"),
        );
      } finally {
        setIsReviewing(false);
        setIsStreamingReview(false);
      }
    },
    [selectedReviewModel, validateReview],
  );

  const clearReviewContent = useCallback(() => {
    setReviewContent("");
  }, []);

  return {
    isReviewing,
    selectedReviewModel,
    reviewContent,
    isStreamingReview,
    setSelectedReviewModel,
    handlePromptReview,
    clearReviewContent,
  };
}
